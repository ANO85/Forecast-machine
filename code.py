import streamlit as st
import pandas as pd
import numpy as np
from scipy import stats
from statsmodels.tsa.holtwinters import SimpleExpSmoothing
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import io

# Configuration de l'application Streamlit
st.set_page_config(page_title="Pr√©visions de Ventes", page_icon="üìä")

# Titre de l'application
st.title("Pr√©visions de Ventes - Outil de Forecast")

# Fonction pour charger et pr√©traiter les donn√©es
def load_and_preprocess_data(uploaded_file):
    try:
        # Lecture du fichier Excel
        df = pd.read_excel(uploaded_file)
        
        # Nettoyage des noms de colonnes (suppression des espaces, conversion en minuscules)
        df.columns = df.columns.str.strip().str.lower()
        
        # V√©rification des colonnes requises
        required_columns = ['date', 'customer group', 'item', 'qty']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            st.error(f"Colonnes manquantes : {', '.join(missing_columns)}")
            st.write("Colonnes actuellement pr√©sentes :", list(df.columns))
            return None
        
        # Renommage des colonnes pour standardisation
        col_mapping = {
            'date': 'Date',
            'customer group': 'Customer group',
            'item': 'Item',
            'qty': 'Qty'
        }
        df = df.rename(columns=col_mapping)
        
        # Conversion de la colonne Date en datetime
        df['Date'] = pd.to_datetime(df['Date'])
        
        # Conversion Qty en num√©rique, gestion des valeurs non-num√©riques
        df['Qty'] = pd.to_numeric(df['Qty'], errors='coerce').fillna(0)
        
        # Exclusion des valeurs aberrantes (plus de 3 √©carts-types de la moyenne)
        # SUPPRESSION de ce filtrage ici pour √©viter un double filtrage
        # Les filtrages sp√©cifiques seront appliqu√©s dans les fonctions de pr√©vision si n√©cessaire
        
        # Tri des donn√©es par date
        df = df.sort_values('Date')
        
        # Afficher l'aper√ßu des donn√©es avec les colonnes correctes
        st.write("Aper√ßu des donn√©es apr√®s pr√©traitement:")
        st.dataframe(df[['Date', 'Customer group', 'Item', 'Qty']].head())
        
        return df
    except Exception as e:
        st.error(f"Erreur de chargement du fichier : {e}")
        return None

# M√©thode 1 : Moyenne mobile sur 6 mois
def moving_average_forecast(group, last_date, months_to_forecast=12):
    # Groupement par mois
    try:
        # CORRECTION: V√©rifier d'abord si le DataFrame est vide
        if group.empty:
            return None
            
        # Afficher les donn√©es brutes pour debug
        st.write(f"DEBUG - Donn√©es brutes pour l'article s√©lectionn√©:")
        st.dataframe(group[['Date', 'Qty']].sort_values('Date'))
            
        # CORRECTION: Agr√©ger les donn√©es quotidiennes en total mensuel
        # Grouper par mois pour obtenir la somme mensuelle des quantit√©s
        monthly_sales = group.groupby(pd.Grouper(key='Date', freq='M'))['Qty'].sum()
        
        # CORRECTION: Convertir en DataFrame pour une meilleure manipulation
        monthly_sales = monthly_sales.reset_index()
        
        # Afficher les donn√©es mensuelles pour v√©rification
        st.write("DEBUG - Donn√©es mensuelles agr√©g√©es:")
        monthly_view = monthly_sales.copy()
        monthly_view['Date'] = monthly_view['Date'].dt.strftime('%m/%Y')
        st.dataframe(monthly_view)
        
        # Si moins de 6 mois de donn√©es, utiliser la moyenne totale
        if len(monthly_sales) < 6:
            avg_sales = monthly_sales['Qty'].mean()
            ma_forecast = [max(0, avg_sales)] * months_to_forecast
            st.write(f"DEBUG - Moins de 6 mois de donn√©es, moyenne utilis√©e: {avg_sales}")
        else:
            # CORRECTION: Utiliser les 6 derniers mois pour la moyenne mobile
            recent_sales = monthly_sales.tail(6)['Qty']
            st.write("DEBUG - 6 derniers mois utilis√©s pour la moyenne mobile:")
            st.dataframe(monthly_sales.tail(6))
            
            avg_sales = recent_sales.mean()
            ma_forecast = [max(0, avg_sales)] * months_to_forecast
            
            st.write(f"DEBUG - Moyenne mobile calcul√©e sur les 6 derniers mois: {avg_sales}")
        
        # G√©n√©rer des dates correctes pour les 12 prochains mois
        forecast_dates = []
        forecast_start = last_date.replace(day=1) + pd.offsets.MonthBegin(1)
        for i in range(months_to_forecast):
            forecast_dates.append(forecast_start + pd.offsets.MonthBegin(i))
        
        forecast_df = pd.DataFrame({
            'Date': forecast_dates,
            'Qty_Forecast_MA': ma_forecast
        })
        
        # Formatage des dates
        forecast_df['Date'] = forecast_df['Date'].dt.strftime('%d/%m/%Y')
        
        return forecast_df
    except Exception as e:
        st.error(f"Erreur de pr√©vision par moyenne mobile : {e}")
        print(f"Erreur d√©taill√©e: {e}")
        import traceback
        st.code(traceback.format_exc())
        return None

# M√©thode 2 : Lissage exponentiel simple
def exponential_smoothing_forecast(group, last_date, months_to_forecast=12):
    try:
        # CORRECTION: V√©rifier d'abord si le DataFrame est vide
        if group.empty:
            return None
            
        # Groupement par mois
        monthly_sales = group.groupby(pd.Grouper(key='Date', freq='M'))['Qty'].sum().reset_index()
        
        # Si pas assez de donn√©es, utiliser la moyenne
        if len(monthly_sales) < 3:  # On a besoin d'au moins 3 points pour un bon lissage
            avg_sales = monthly_sales['Qty'].mean()
            es_forecast = [max(0, avg_sales)] * months_to_forecast
        else:
            # CORRECTION: Utiliser uniquement les donn√©es r√©centes (jusqu'√† 12 derniers mois)
            train_data = monthly_sales['Qty'].tail(min(12, len(monthly_sales)))
            
            # Param√®tre alpha plus petit pour moins de r√©activit√© aux derni√®res observations
            alpha = 0.2  # Valeur fixe au lieu de l'optimisation qui peut √™tre instable
            model = SimpleExpSmoothing(train_data).fit(smoothing_level=alpha, optimized=False)
            
            es_forecast = model.forecast(steps=months_to_forecast).tolist()
            
            # √âviter les valeurs n√©gatives et les valeurs aberrantes
            # Limiter les pr√©visions √† 150% de la moyenne historique pour √©viter les surestimations
            avg_historical = train_data.mean()
            max_forecast = avg_historical * 1.5
            es_forecast = [max(0, min(x, max_forecast)) for x in es_forecast]
        
        # G√©n√©rer des dates correctes pour les prochains mois
        forecast_dates = []
        forecast_start = last_date.replace(day=1) + pd.offsets.MonthBegin(1)
        for i in range(months_to_forecast):
            forecast_dates.append(forecast_start + pd.offsets.MonthBegin(i))
        
        forecast_df = pd.DataFrame({
            'Date': forecast_dates,
            'Qty_Forecast_ES': es_forecast
        })
        
        # Formatage des dates
        forecast_df['Date'] = forecast_df['Date'].dt.strftime('%d/%m/%Y')
        
        return forecast_df
    except Exception as e:
        st.error(f"Erreur de pr√©vision par lissage exponentiel : {e}")
        return None

# M√©thode 3 : R√©gression lin√©aire simple
def linear_regression_forecast(group, last_date, months_to_forecast=12):
    try:
        # CORRECTION: V√©rifier d'abord si le DataFrame est vide
        if group.empty:
            return None
            
        # Groupement par mois
        monthly_sales = group.groupby(pd.Grouper(key='Date', freq='M'))['Qty'].sum().reset_index()
        
        # Si pas assez de donn√©es, utiliser la moyenne
        if len(monthly_sales) < 3:  # Au moins 3 points pour une r√©gression fiable
            avg_sales = monthly_sales['Qty'].mean()
            lr_forecast = [max(0, avg_sales)] * months_to_forecast
        else:
            # CORRECTION: Utiliser uniquement les donn√©es r√©centes (jusqu'√† 12 derniers mois)
            recent_data = monthly_sales.tail(min(12, len(monthly_sales)))
            X = np.arange(len(recent_data)).reshape(-1, 1)
            y = recent_data['Qty'].values
            
            # R√©gression lin√©aire
            slope, intercept, r_value, p_value, std_err = stats.linregress(X.ravel(), y)
            
            # Si la tendance est n√©gative ou trop accentu√©e, limiter son impact
            if slope < 0:
                # Si tendance n√©gative, att√©nuer pour √©viter des pr√©visions trop pessimistes
                slope = slope / 2
            elif slope > 0 and slope > np.mean(y) / 12:
                # Si la pente est trop forte (croissance > moyenne/an), la limiter
                slope = np.mean(y) / 12
            
            # Calculer la moyenne des donn√©es r√©centes pour r√©f√©rence
            avg_recent = np.mean(y)
            
            # Pr√©vision des prochains mois bas√©e sur la r√©gression modifi√©e
            last_index = len(recent_data) - 1
            lr_forecast = []
            
            for i in range(months_to_forecast):
                # Calculer la valeur pr√©dite
                predicted = slope * (last_index + 1 + i) + intercept
                
                # Limiter la pr√©vision √† 150% de la moyenne r√©cente pour √©viter les surestimations
                max_forecast = avg_recent * 1.5
                
                # Appliquer les limites (jamais n√©gatif, jamais > 150% de la moyenne)
                lr_forecast.append(max(0, min(predicted, max_forecast)))
        
        # G√©n√©rer des dates correctes pour les prochains mois
        forecast_dates = []
        forecast_start = last_date.replace(day=1) + pd.offsets.MonthBegin(1)
        for i in range(months_to_forecast):
            forecast_dates.append(forecast_start + pd.offsets.MonthBegin(i))
        
        forecast_df = pd.DataFrame({
            'Date': forecast_dates,
            'Qty_Forecast_LR': lr_forecast
        })
        
        # Formatage des dates
        forecast_df['Date'] = forecast_df['Date'].dt.strftime('%d/%m/%Y')
        
        return forecast_df
    except Exception as e:
        st.error(f"Erreur de pr√©vision par r√©gression lin√©aire : {e}")
        return None

# Interface Streamlit principale
def main():
    # Initialisation des variables de session pour stocker les r√©sultats
    if 'forecast_calculated' not in st.session_state:
        st.session_state.forecast_calculated = False
    if 'excel_data' not in st.session_state:
        st.session_state.excel_data = None
    
    # T√©l√©chargement du fichier
    uploaded_file = st.file_uploader("Charger le fichier historique des ventes", 
                                     type=['xlsx', 'xls'], 
                                     help="Fichier Excel avec colonnes : Date, Customer group, Item, Qty")
    
    # Ajout d'un s√©lecteur pour choisir l'horizon des pr√©visions
    months_to_forecast = st.selectbox(
        "Horizon de pr√©vision (mois)",
        options=[3, 6, 12, 24],
        index=1  # 6 mois par d√©faut
    )
    
    # Param√®tre pour contr√¥ler le nombre de mois historiques √† utiliser
    historic_months = st.slider(
        "Nombre de mois d'historique √† utiliser",
        min_value=3, 
        max_value=24, 
        value=6,
        help="Nombre de mois d'historique √† utiliser pour calculer les pr√©visions"
    )
    
    # Option pour filtrer les valeurs extr√™mes
    filter_outliers = st.checkbox("Filtrer les valeurs extr√™mes", value=True, 
                                 help="Supprimer les valeurs qui d√©passent 3 √©carts-types de la moyenne")
    
    # AJOUT: √âl√©ment de recherche pour un article sp√©cifique
    article_search = st.text_input("Rechercher un article sp√©cifique (optionnel)")
    
    if uploaded_file is not None:
        # R√©initialiser les calculs si un nouveau fichier est charg√©
        if 'current_file' not in st.session_state or st.session_state.current_file != uploaded_file.name:
            st.session_state.forecast_calculated = False
            st.session_state.excel_data = None
            st.session_state.current_file = uploaded_file.name
            
        # Chargement et pr√©traitement des donn√©es
        df = load_and_preprocess_data(uploaded_file)
        
        if df is not None:
            # CORRECTION: Application du filtre des valeurs aberrantes APR√àS le chargement et SEULEMENT si demand√©
            if filter_outliers:
                # Cr√©er une copie avant filtrage pour comparaison
                df_before = df.copy()
                
                # Filtrer les valeurs aberrantes par article et groupe client
                for (item, group), subset in df.groupby(['Item', 'Customer group']):
                    if len(subset) > 10:  # Assez de donn√©es pour calculer des statistiques fiables
                        mean_qty = subset['Qty'].mean()
                        std_qty = subset['Qty'].std()
                        if std_qty > 0:  # √âviter la division par z√©ro
                            # R√©cup√©rer les indices des lignes √† conserver
                            valid_idx = subset[abs(subset['Qty'] - mean_qty) <= 3 * std_qty].index
                            # Filtrer le DataFrame principal
                            df = df[df.index.isin(valid_idx) | ~((df['Item'] == item) & (df['Customer group'] == group))]
                
                # Afficher un r√©sum√© du filtrage
                removed = len(df_before) - len(df)
                if removed > 0:
                    st.info(f"{removed} enregistrements identifi√©s comme aberrants ont √©t√© supprim√©s ({removed/len(df_before)*100:.1f}%)")
            
            # Trouver la derni√®re date dans le jeu de donn√©es
            last_date = df['Date'].max()
            
            # AJOUT: Si recherche d'article sp√©cifique, filtrer les donn√©es
            if article_search:
                df_search = df[df['Item'].str.contains(article_search, case=False)]
                if not df_search.empty:
                    st.success(f"Article trouv√©: {len(df_search)} enregistrements correspondant √† '{article_search}'")
                    st.write("Aper√ßu des donn√©es pour cet article:")
                    st.dataframe(df_search)
                    
                    # Afficher les ventes mensuelles pour cet article
                    st.write("Ventes mensuelles pour cet article:")
                    monthly_data = df_search.groupby([pd.Grouper(key='Date', freq='M'), 'Customer group'])['Qty'].sum().reset_index()
                    monthly_data['Date'] = monthly_data['Date'].dt.strftime('%m/%Y')
                    st.dataframe(monthly_data)
                else:
                    st.warning(f"Aucun article correspondant √† '{article_search}' trouv√© dans les donn√©es.")
            
            # Affichage des informations utiles
            with st.expander("Informations sur les donn√©es"):
                st.write(f"Derni√®re date dans les donn√©es : {last_date.strftime('%d/%m/%Y')}")
                st.write(f"Date de d√©but des pr√©visions : {(last_date.replace(day=1) + pd.offsets.MonthBegin(1)).strftime('%d/%m/%Y')}")
                st.write("Statistiques descriptives des ventes:")
                st.dataframe(df.groupby(['Customer group', 'Item'])['Qty'].describe())
            
            # R√©cup√©ration des groupes uniques
            customer_groups = df['Customer group'].unique()
            items = df['Item'].unique()
            
            # Limiter les donn√©es historiques en fonction du nombre de mois s√©lectionn√©
            if historic_months > 0:
                cutoff_date = last_date - pd.DateOffset(months=historic_months)
                df_filtered = df[df['Date'] >= cutoff_date]
                if len(df_filtered) > 0:  # V√©rifier qu'il reste des donn√©es
                    df = df_filtered
                    st.info(f"Utilisation des {historic_months} derniers mois d'historique (√† partir de {cutoff_date.strftime('%d/%m/%Y')})")
            
            # Si les calculs n'ont pas encore √©t√© effectu√©s, les lancer
            if not st.session_state.forecast_calculated or st.button("Recalculer les pr√©visions"):
                # Dictionnaires pour stocker les r√©sultats
                ma_results = {}
                es_results = {}
                lr_results = {}
                
                # Barre de progression
                st.write("Calcul des pr√©visions en cours...")
                progress_bar = st.progress(0)
                progress_status = st.empty()
                total_combinations = len(items) * len(customer_groups)
                counter = 0
                
                # Calcul des pr√©visions pour chaque combinaison
                for item in items:
                    for group in customer_groups:
                        # Mise √† jour de la barre de progression
                        counter += 1
                        progress_bar.progress(counter / total_combinations)
                        progress_status.text(f"Traitement: {counter}/{total_combinations} - Item: {item}, Groupe: {group}")
                        
                        # Filtrage des donn√©es
                        subset = df[(df['Customer group'] == group) & (df['Item'] == item)]
                        
                        # CORRECTION: Ajouter un debug sp√©cifique pour l'article recherch√©
                        is_target_item = article_search and item.lower() == article_search.lower()
                        
                        # V√©rifier s'il y a des donn√©es pour cette combinaison
                        if not subset.empty:
                            # Ajout d'un √©tat d'avancement plus d√©taill√©
                            with st.expander(f"D√©tails pour {item} (Groupe: {group})", expanded=is_target_item):
                                st.write(f"Nombre d'enregistrements: {len(subset)}")
                                # Afficher les ventes mensuelles pour inspection
                                monthly_data = subset.groupby(pd.Grouper(key='Date', freq='M'))['Qty'].sum().reset_index()
                                monthly_data['Date'] = monthly_data['Date'].dt.strftime('%m/%Y')
                                monthly_avg = monthly_data['Qty'].mean()
                                st.write(f"Moyenne mensuelle: {monthly_avg:.2f} unit√©s")
                                st.dataframe(monthly_data)
                                
                                # SI c'est l'article recherch√©, afficher plus de d√©tails
                                if is_target_item:
                                    st.write("Analysons en d√©tail cet article sp√©cifique")
                                    # Afficher tous les enregistrements bruts
                                    st.write("Donn√©es brutes:")
                                    st.dataframe(subset[['Date', 'Qty']].sort_values('Date'))
                            
                            # Calcul des pr√©visions avec le nombre de mois sp√©cifi√©
                            ma_forecast = moving_average_forecast(subset, last_date, months_to_forecast)
                            es_forecast = exponential_smoothing_forecast(subset, last_date, months_to_forecast)
                            lr_forecast = linear_regression_forecast(subset, last_date, months_to_forecast)
                            
                            # Stockage des r√©sultats
                            key = f"{item} - {group}"
                            
                            if ma_forecast is not None:
                                ma_results[key] = ma_forecast
                            
                            if es_forecast is not None:
                                es_results[key] = es_forecast
                            
                            if lr_forecast is not None:
                                lr_results[key] = lr_forecast
                
                # Effacer le statut de progression une fois termin√©
                progress_status.empty()
                st.success("Calcul des pr√©visions termin√©!")
                
                # Exemple de pr√©visions pour un article sp√©cifique
                if items.size > 0 and customer_groups.size > 0:
                    # Si un article est recherch√©, l'utiliser comme exemple
                    if article_search and article_search in items:
                        sample_item = article_search
                    else:
                        sample_item = items[0]
                    
                    sample_group = customer_groups[0]
                    sample_key = f"{sample_item} - {sample_group}"
                    
                    with st.expander("Exemple de pr√©visions", expanded=True):
                        if sample_key in ma_results:
                            st.write(f"Pr√©visions pour {sample_item} (Groupe: {sample_group}):")
                            st.write("Moyenne mobile:")
                            st.dataframe(ma_results[sample_key])
                
                # G√©n√©rer le fichier Excel en m√©moire
                excel_buffer = io.BytesIO()
                
                # Utiliser openpyxl si disponible
                try:
                    import openpyxl
                    excel_engine = 'openpyxl'
                except ImportError:
                    excel_engine = None
                
                with pd.ExcelWriter(excel_buffer, engine=excel_engine) as writer:
                    # Onglet Moyenne Mobile
                    if ma_results:
                        ma_combined = pd.concat([
                            pd.DataFrame({
                                'Item': [k.split(' - ')[0]] * len(v),
                                'Customer group': [k.split(' - ')[1]] * len(v),
                                **v
                            }) 
                            for k, v in ma_results.items()
                        ])
                        ma_combined.to_excel(writer, sheet_name='Moyenne_Mobile', index=False)
                    
                    # Onglet Lissage Exponentiel
                    if es_results:
                        es_combined = pd.concat([
                            pd.DataFrame({
                                'Item': [k.split(' - ')[0]] * len(v),
                                'Customer group': [k.split(' - ')[1]] * len(v),
                                **v
                            }) 
                            for k, v in es_results.items()
                        ])
                        es_combined.to_excel(writer, sheet_name='Lissage_Exponentiel', index=False)
                    
                    # Onglet R√©gression Lin√©aire
                    if lr_results:
                        lr_combined = pd.concat([
                            pd.DataFrame({
                                'Item': [k.split(' - ')[0]] * len(v),
                                'Customer group': [k.split(' - ')[1]] * len(v),
                                **v
                            }) 
                            for k, v in lr_results.items()
                        ])
                        lr_combined.to_excel(writer, sheet_name='Regression_Lineaire', index=False)
                    
                    # Onglet de comparaison des m√©thodes
                    if ma_results and es_results and lr_results:
                        # Prendre un √©chantillon pour comparer
                        sample_comparisons = []
                        
                        # Si un article est recherch√©, l'utiliser en priorit√©
                        if article_search:
                            target_keys = [k for k in ma_results.keys() if article_search.lower() in k.lower()]
                            keys_to_process = target_keys[:5] + [k for k in list(ma_results.keys())[:10] if k not in target_keys]
                        else:
                            keys_to_process = list(ma_results.keys())[:10]
                            
                        for key in keys_to_process:
                            key_parts = key.split(' - ', 1)
                            if len(key_parts) != 2:
                                continue
                                
                            item, group = key_parts
                            if key in ma_results and key in es_results and key in lr_results:
                                try:
                                    for month in range(min(12, len(ma_results[key]))):
                                        date_str = ma_results[key]['Date'].iloc[month]
                                        ma_val = ma_results[key]['Qty_Forecast_MA'].iloc[month]
                                        es_val = es_results[key]['Qty_Forecast_ES'].iloc[month]
                                        lr_val = lr_results[key]['Qty_Forecast_LR'].iloc[month]
                                        
                                        sample_comparisons.append({
                                            'Item': item,
                                            'Customer group': group,
                                            'Date': date_str,
                                            'Moyenne Mobile': ma_val,
                                            'Lissage Exponentiel': es_val,
                                            'R√©gression Lin√©aire': lr_val
                                        })
                                except (IndexError, KeyError) as e:
                                    print(f"Erreur lors de l'acc√®s aux donn√©es de pr√©vision pour {key}: {e}")
                        
                        if sample_comparisons:
                            comparison_df = pd.DataFrame(sample_comparisons)
                            comparison_df.to_excel(writer, sheet_name='Comparaison_Methodes', index=False)
                
                # Enregistrement du r√©sultat dans la session
                excel_buffer.seek(0)
                st.session_state.excel_data = excel_buffer.getvalue()
                st.session_state.forecast_calculated = True
            
            # Affichage du bouton de t√©l√©chargement si le calcul est termin√©
            if st.session_state.forecast_calculated and st.session_state.excel_data is not None:
                st.download_button(
                    label="üìä T√©l√©charger les pr√©visions",
                    data=st.session_state.excel_data,
                    file_name='Previsions_Ventes.xlsx',
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    key='download_excel'
                )

# Point d'entr√©e principal
if __name__ == "__main__":
    main()